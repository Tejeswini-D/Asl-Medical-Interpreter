# ASL Medical Interpreter

Real-time ASL interpreter for emergency medical communication.

## Tech Used
- Python
- OpenCV
- MediaPipe
- Scikit-learn

## How to Run
```bash
python live_predict.py
## ðŸ“‚ Project Structure
â”œâ”€â”€ dataset_capture.py # Record gestures using webcam
â”œâ”€â”€ record_i.py # Record only the "I" gesture
â”œâ”€â”€ extract_landmarks.py # Extract MediaPipe landmarks
â”œâ”€â”€ merge_datasets.py # Merge CSV datasets
â”œâ”€â”€ inspect_csv.py # Check dataset structure
â”œâ”€â”€ train_model.py # Train ML model
â”œâ”€â”€ predict_live.py # Live ASL prediction
â”œâ”€â”€ yes_no.py # Record Yes/No gestures
â”œâ”€â”€ README.md

## ðŸ“¹ Recording Gestures
To record gestures from your webcam:
```bash
python dataset_capture.py
Notes
Dataset CSV files and trained models are not uploaded to GitHub
Clear lighting and consistent hand position improve accuracy
The model can be expanded with additional ASL signs